# 正则表达式

## 系统符号概念

- 通配符号（用于查找文件信息）：`*`、`{}`
- 正则符号（grep、sed、awk）
  1. 可以处理1文件中的数据信息
  2. 基础正则符号 basic regular expression（BRE）
  3. 扩展正则符号 extended regular expression（ERE）

## 系统中的普通符号

1. 美元符号：$

2. 井号符号：#

3. 叹号符号：! 

   其中一个作用是取反，在大部分地方都可以尝试通用

   ```shell
   find /dev/ -type f ! -name "*.txt"
   ```

4. 竖线符号：|

   竖线符号常与xargs命令连用，xargs命令表示将多个内容整合成一行显示

   ```shell
   xargs < passwd     # 语法与tr命令相似
        # -n：分组显示，不加参数或不使用此选项都会整合成1行显示
   xargs -n2 < passwd     # 以2行内容为1组显示，简而言之就是将原文档的每2行信息整合成1行显示
   
   find ${pwd} -type f -name "*.txt" | xargs rm     # 删除通过find命令查找的文件
        # 此命令中，如果不使用xargs而是直接rm，那么rm命令不会生效
        # xargs命令不识别别名信息，所以rm指令不需要带参数f
   
   find ${pwd} -type f -name "*.txt" -exec rm -f {} \;    # 实现与上例一样的效果
   find ${pwd} -type f -name "*.txt" -delete    # 使用find本身的选项删除查找结果
   ```

### xargs指令

一般情况下xargs指令会配合管道符使用，xargs指令会将前一条指令的结果放在后一条指令的尾部位置，例如：

```shell
find /home/hebor/ -type f -name "*.txt" | xargs cp -a /backup/    # 本条命令的本意是将find查找的结果备份到/backup/目录中，但后半条指令实际的执行效果如下
    [xargs] cp -a /backup/ FileName1.txt FileName2.txt    # 以2个文件简单示例，可以看出xargs将查找的结果放到cp指令的尾部后，cp指令的意义就被改变了

find /home/hebor/ -type f -name "*.txt" | xargs -i cp -a {} /backup/    # 通过-i选项替换上一指令结果的位置，实现备份
    # -i：--replease=[R]，i选项默认使用{}作为find指令的结果集

find /home/hebor/ -type f -name "*.txt" | xargs --replace=R cp -a R /backup/    # 实现同样的效果，R类似变量名，可替换
    # 类似于将find查找的结果赋值给R，然后通过更改R的位置实现cp指令

find /home/hebor/ -type f -name "*.txt" | xargs cp -a -t /backup/    # 或者直接通过cp命令的-t选项指定目标目录
```

有时候使用`${}`或` `` `反引号引用命令结果时会莫名报错，可能是因为别名的问题，可以再使用反斜杠再试试，例如`${\which rm}`

### 重定向符号

重定向的2种类型：标准重定向、错误重定向

```shell
ech test >> /home/hebor/log.txt 2>&1    # 错误或正确的提示信息都保存
echo test &>> /home/hebor/log.txt        # 上例的另一种写法
echo test 1>> /home/hebor/log.txt 2>> /home/hebor/error.txt        # 正确提示与错误提示分开
```

### 路径符号

路径符号包括：`.`，`..`，`-`，`~`

主要是关于cd命令中的一个选项`-`，通过man手册查看cd命令可以看到，`-`表示系统环境变量`$OLDPWD`

## 通配符 & 正则符

通配符：用于匹配文件名称信息，便于快速查找文件

正则符：用于匹配文件内容信息，常被awk、sed、grep、python、java等程序或代码调用

通配符：`*`、`{}`

```shell
echo {01..100..2}        # 输出规则不连续序列，以2为间隔
echo {a,b}{c,d}        # 输出组合序列
echo A{,B}    # 特殊组合序列，输出结果为A和AB，等同于连续输出原文件和组合文件
```

正则符：用于查找文件中的文本内容

符号分类：

1. 基础正则表达式 BRE：grep、sed、awk
2. 扩展正则表达式 ERE：grep -E/egrep、sed -r、awk

正则符号使用注意事项：

1. 以行信息进行过滤处理 sed、awk
2. 正则表达式符号禁止中文

### 基础正则符号说明

基础正则符号包括：`^`、`$`、`.`、`*`、`[]`、`[^]`、`\`

示例：创建实验环境

```
I am oldboy teacher!
I teach linux.

I like badminton ball ,billiard ball and chinese chess!
my blog is http://oldboy.blog.51cto.com
our site is http://www.etiantian.org
my qq num is 49000448

not 4900000448
my god ,i am not oldbey,but OLDBOY!
```

示例：基础正则表达式符号解析

```shell
# ^：表示以某字符开头
grep "^m" test.txt    # 过滤测试文件中以m开头的内容

# $：表示以某字符结尾
grep "m$" test.txt    # 过滤测试文件中以m结尾的内容
grep "^$" test.txt    # 过滤文件空行信息

# .：表示任意一个字符；*：表示任意数量的前一个字符
grep "^m.*m$" test.txt    # 过滤以m开头并以m结尾的行；.和*联合使用表示匹配所有内容
grep "90*" test.txt    # 过滤文本中包含多个或0个 0字符 的行
    # 关于*的使用需要特别注意2点：过滤前一个字符、出现0次或多次
    # 如果将此示例中的条件从 "90*" 改为 "0*"，那么grep会将整个测试文件的文本都匹配，因为0字符出现0次的行被匹配
    # 通过grep指令的-o选项可以查看条件为"90*"时，grep匹配的结果分为2种：9 或 9000，分别代表0字符出现0次与多次

# \：转义符
grep "\.$" test.txt    # 将有特殊意义的符号转义为普通字符
echo -e "first paragrpph\nsecond paragraph"    # 换行符
    \n：换行
	\t：制表

# []：表示单独匹配括号中的每一个字符；[^ ]：表示对中括号中匹配的内容取反
grep "[ol]" test.txt    # 匹配o字符或l字符的行，"[]"括号中的每一个字符都是逻辑或关系
grep -E "o|l" test.txt    # 实现与上例一样的效果
grep -n "[0-9]" test.txt    # 匹配所有数字，显示行号。括号中的数字也可替换成字符a-z，表示匹配所有字符
    -i：忽略大小写
    -n：显示行号
    -E：支持扩展正则
    -v：反选
    -c：统计符合匹配条件的行数
grep -Ev "^#|^$" test.txt    # 排除空行和注释

# 示例：过滤以m或I开头的行
grep "^[mI]" test.txt
sed -n "/^[mI]/p" test.txt
awk "/^[mI]/" test.txt
```

> **补充：正则符号特性**

正则符号匹配字符信息时，拥有贪婪特性。例如，本意通过如下指令截取测试文本中的字符串"I like badminton b"时

```shell
grep "^I l.*b" test.txt    # 贪婪特性会持续匹配以b结尾的单词，直到本行文本中的最后一个b字符
	# 此处实际匹配出的内容是"I like badminton ball ,billiard b"
    # 为了更精准的匹配，匹配条件应该尽可能的具备唯一性
grep "^I l.*n b" test.txt    # 避免贪婪属性
```

> **补充：grep的过滤规则**

grep以行信息过滤，通过`-o`选项可以查看grep过滤时，是匹配的文本行内容中的哪一个字符

```shell
grep "." test.txt -o        #  使用 . 过滤时，每一行的每一个字符都会被匹配
grep "^m" test.txt -o    # 与上例对比
```

> **补充：检查文件尾部的空格**

通常文本开头是否有空格很好判断，但尾部不便查看，有2种方式显示尾部结尾信息

1. 通过底行命令模式设置`set list`
2. 通过cat指令的-A选项查看`cat -A filename`

### 扩展正则符号说明

扩展正则符包括：`+`、`|`、`()`、`{}`、`?`

示例：新建测试文件

```
zhao  110105199003065412
qian  120107198006077652
sun   310107198006077652
li    120109198006077652
zhou  897107198006077652
feng  text
wu    12010719800607765X
chu   content
zheng 311007198006077652
wang  120107198006077652
```

示例：扩展正则表达式符号解析

```shell
# +：表示前一个字符出现1次或以上。与*的区别就在于+号不匹配0次
egrep "0+" test.txt    # 匹配0字符出现1次以上的行
egrep "[0-9]+" id.txt -o    # 匹配数字出现多次的行。此处-o会将行信息作为整体输出，因为"[0-9]+"会匹配整行内容的所有数字
grep "[0-9]" id.txt -o    # 与上例对比
    # 扩展正则符+会常与[]符配合使用，用于匹配多个不同的连续字符

# |：表示匹配多个信息时作为逻辑或运算
egrep "oldboy|oldbey" test.txt    # 可以连续多次进行|匹配
sed -rn "/oldboy|oldbey/p" test.txt    # -r选项识别扩展正则符
awk "/oldboy|oldbey/" test.txt

# ()：表示将匹配的信息作为一个整体进行查询。与[]符对比，()符针对括号内的字符串不再拆分匹配每一个单独的字符，而是字符串整体匹配
egrep "(oldboy)" test.txt    # 过滤oldboy字符串

# {}：指定前一个字符连续匹配次数。{n,m}是标准语法，匹配n~m次；四种用法：{n,m}、{n}、{n,}、{,m}
egrep "0{1,3}" test.txt    # 过滤0字符出现1~3次的行，在本例中也限制了匹配次数，一行中出现多个0时最多只匹配3个0，多余的字符换行匹配
egrep "0+" test.txt    # 结果上来看与上例并无区别，可以通过-o选项查看区别
egrep "0{3}" test.txt    # 只匹配0字符连续出现n次的行

# ?：表示匹配前一个字符出现0次或1次
egrep "0?" test.txt -o
```

> **补充：关于()符在sed命令中的特殊作用**

在sed命令中()符用于后项引用前项。sed命令替换信息操作中，将不变的信息用()符声明

```shell
echo 123456 | sed "s#123456#<123456>#g"		# 想实现的效果
echo 123456 | sed "s#......#<123456>#g"		# 首次优化。将数字用6个 . 符号替代
echo 123456 | sed "s#.*#<123456>#g"		# 二次优化。将6个 . 符号用基础正则符优化
echo 123456 | sed -r "s#(.*)#<\1>#g"	# 优化结果。(.*)表示将6个数字视做一个整体（前项），"\1"表示前项，在"\1"两侧加上"<>"号等同于在前项两侧加上尖括号
echo 123456 | sed -r "s#(..)(..)(..)#<\1><\2><\3>#g"	# 将前项分开处理。后项的数字分别代表前项的第几个括号内容
echo 123456 | sed -r "s#(.{2})#<\1>#g"  # 上例简化
```

### 正则符使用误区

以`^`符和`*`符的区别为例，辨别以下两个示例的区别

```shell
find /etc/ -type f -name "network*"    # 通配符。根据文件名称查找文件
find /etc/ -type f -name "^network"    # 正则符。根据文件内容过滤信息
```

两个示例乍一看似乎是一个意思，此处就容易涉及到通配符和正则符的误区。再次重申：通配符用于匹配文件名称信息，便于快速查找文件；正则符用于匹配文件内容信息，常被awk、sed、grep、python、java等程序或代码调用

### 正则表达式实践

```shell
# 获取IP的3种方式：sed、awk、grep
# 1. 定位信息所在行
ip address show eth0 | sed -n "3p"
ip address show eth0 | awk 'NR==3'    # NR表示Number Row；一个=号是赋值，必须使用==号
ip address show eth0 | grep "inet "    # inet后面的空格必须有，否则会过滤出ipv6信息

# 2. 截取指定信息
ip add show eth0 | sed -n "3p" | sed -r "s#(.*inet )([0-9.]*)(/.*)#\2#g"    # sed 实现需求，此例中也可以只声明一个前项
ip add show eth0 | sed -n "3p" | sed -r "s#.*inet |/.*##g"    # 二次精简
ip add show eth0 | sed -nr '3s#.*inet |/.*##gp'    # sed 优化结果

ip add show eth0 | awk "NR==3" | awk '{print $2}'    # awk实现需求，默认awk截取列信息时按空格截取
ip add show eth0 | awk "NR==3" | awk -F "[ /]" '{print $6}'    # 使用-F选项配合ERE将/符也视作awk的分隔符
ip add show eth0 | awk -F "[ /]+" 'NR==3 {print $3}'    # awk 优化结果
    # awk截取信息时，默认没有使用-F指定分隔符信息时，采用空格切分列，但是一行字符开头的多个空格会忽略不记

ip add show eth0 | grep "inet " | egrep "[0-9\.]+" -o | head -n 1    # 巧妙的应用-o选项输出IP
    # 关于"[0-9\.]"在此处属于取巧了，匹配IP严格意义上的写法应该是"[0-9]+\.[0-9]\.[0-9]\.[0-9]+"或"([0-9]+\.){3}[0-9]+"
    # grep 优化结果 "([0-9]+\.?){4}"

# 获取文件权限信息：sed、awk
stat /etc/hosts | sed -n '4p' | sed -r 's#.*s: \(|/-.*##g'

stat /etc/hosts | awk 'NR==4' | awk -F "[ (/]" '{print $3}'    # 实现需求
stat /etc/hosts | awk -F "[(/]" 'NR==4 {print $2}'    # awk 优化

stat -c %a /etc/hosts    # 直接通过命令获取权限
```

sed擅长取行、替换修改文件信息，awk擅长取列、数据统计

> **获取信息的第4种方式（思路）**

在linux系统中，是否存在一些命令能够更加简单直接的获取到想要的信息，例如获取IP。有些重要的系统信息，会有相应的命令或参数直接显示

```shell
hostname    # 查看主机名
hostname -i    # -i选项表示获取与本机hostname对应的IP。/etc/hosts文件
hostname -I    # -I选项表示获取本机的所有IP
```

> **正则表达式补充**

```shell
[:alnum:]：代表英文字母大小写及数字
[:alpha:]：代表任何英文大小写字母
[:blank:]：代表空格和tab键
[:cntrl:]：代表键盘上的控制键
[:digit:]：代表数字
[:graph:]：除了空格和tab以外的任何键
[:lower:]：代表小写字母
[:print:]：代表任何可以打印出来的字母
[:punct:]：代表标点符号
[:upper:]：代表大写字母
[:space:]：代表任何能产生空白的字元
[:xdigit:]：代表16进制数字类型
```

# sed

sed命令语法：sed [参数信息/选项信息] '条件信息 指令信息' 文件信息

## sed命令执行过程

1. 一次从输入中读取一行数据，输入可以是从文件中读取或从终端读取
2. 依据输入的字符匹配数据
3. 按照输入的命令修改数据
4. 将修改后的数据输出到STDOUT

sed从文件中读取文本时，每换一行就会重新走一遍工作流程；默认情况下，sed每从输入中读取一行数据，不论是否满足匹配条件都会将其输出到屏幕，`-n`选项则是只输出满足条件的行

### 示例：新建测试文件

```shell
101,oldboy,CEO
102,zhaoyao,CTO
103,Alex,COO
104,yy,CFO
105,feixue,CIO
```

### 示例：sed查询操作

```shell
# 1. 按行号查询
sed -n "3p" person.txt    # 查找单行信息
sed -n "3,5p" person.txt    # 查看连续的多行信息
sed -n '3p;5p' person.txt    # 查询不连续的多行信息
sed -n '1~2p' person.txt    # 从第1行开始间隔为2查询信息

# 2. 按字符信息查询
sed -n '/oldboy/p' person.txt    # 查询存在字符串oldboy的行
sed -n '/oldboy/,/Alex/p' person.txt    # 查询oldboy到Alex之间的多行信息
    # 如果后一个字符串Alex没有匹配到，则会显示oldboy后的所有行
    # 如果后一个字符串Alex在文件内容中存在多个，sed会一直匹配到最后一个
```

### 示例：sed增加操作

```shell
sed '1a oldboy123' person.txt    # a表示addend，第1行的下一行添加一行内容oldboy123
sed '1i oldboy123' person.txt    # i表示insert，第1行的上一行添加一行内容
    # 如果不指定条件1时，默认所有信息都匹配条件，所有行都会执行sed添加操作
sed '$a oldboy123' person.txt    # 尾部添加行
sed '3a oldboy123\noldboy456' person.txt    # 利用转义字符添加多行内容
```

### 示例：sed删除操作

```shell
sed '3d' person.txt    # d表示delete，删除第3行
sed -i.bak '3d' person.txt    # 修改文件内容的同时生成原文件的.bak备份
    # 实际上sed命令在不添加-i选项时，所有操作都是临时操作，不会对源文件做出任何改变
sed '/^$/d' person.txt    # 删除空行
```

### 示例：sed替换操作

```shell
sed '3c This third paragraph' person.txt    # 整行替换
sed -n '5s#yy#hebor#gp' person.txt    # 替换某一行的部分内容
    # 使用sed命令替换文件信息时，建议不要同时使用-n和-i，否则替换后的文件不会保存默认输出信息，可能意味着会缺失很多信息
sed "s#$var#testworld#g" person.txt    # 将变量var的值替换成字符串testworld
sed -rn "/oldboy/s#(^.*)CEO#\1UFO#gp" person.txt    # 后项引用前项
    echo 123456 | sed -r "s#.*#<&>#g"    # &符号表示前项匹配到的所有内容
    echo 123456 | sed -r "s#[1-6]{1}#<&>#g"
```

### 示例：将.jpg文件修改为.txt文件

```shell
# 1. 找出需要修改的文件
ls *jpg | xargs -n 1    # 默认ls命令横向显示结果，xargs命令既可以用于横向显示结果，也可用于纵向显示结果

# 2. 模拟修改文件名称
ls *jpg | xargs -n 1 | sed -r "s#(.*)jpg#mv \1jpg \1txt#g"

# 3. 修改文件名
ls *jpg | xargs -n 1 | sed -r "s#(.*)jpg#mv \1jpg \1txt#g" | bash

ls *txt | xargs -n 1 | sed -r "s#(.*)txt#mv & \1jpg#g" | bash    # 将.txt修改回.jpg
rename .jpg .txt test*.jpg    # 专业的名称替换命令
```

### 示例：sed扩展应用

```shell
sed -r '/oldboy/d' person.txt    # 排除行内容中带有 oldboy 字符串的行
sed -n '/oldboy/!p' person.txt    # sed指令搜索结果取反。取反符只能用在sed指令符号前面，也就是p符号前面

sed '/^$/d' test.txt | sed '=' | xargs -n 2    # sed取行内容显示行号。xagrs划分段落时会忽略空行，所以需要先排除空行，sed的"="符表示显示行号
sed "/^$/d; =" test.txt | xargs -n 2 -L 2    # 上例优化。通过;号分隔sed的多个命令

echo student{01..05} | xargs -n 1 | sed 's#.*#useradd & \&\& echo &:$(tr -cd "[[:alnum:]]" < /dev/urandom | head -c 6) | tee -a ./passwd.log | chpasswd#g' | bash    # 批量创建用户，并将随机设置的6位密码保存到指定文件
```

`-L 2`参数表示xargs命令每次仅传递2行文本内容作为参数，在这个示例中如果不使用`-L`参数，xargs默认以空格来分割文本内容，这将会导致分割后的内容难以查看

> **补充：sed操作指令**

```shell
[!]p：显示输出信息（input）
[!]i：插入文字信息（insert）
[!]a：追加文字信息（append）
[!]d：删除文字信息（delete）
[!]s：替换文字信息（substitution）
[!]c：整行信息替换
```

# awk

`gawk - pattern scanning and processing language`，awk全名gawk

命令语法：awk [参数信息 -F -v]' '模式信息{动作信息}' 文件信息

## awk命令执行过程

1. 按行读取文件信息
2. 判断是否符合匹配条件
3. 匹配条件时，按执行动作处理（awk是没有默认输出的，如果没有执行动作print，则不会打印输出）
4. 不匹配条件时，继续读取下一行重复上述过程，直至文件结尾

### 示例：创建测试环境文件

```shell
cat > awk_test.txt << EOF
> Zhang Dandan 41117397 :250:100:175
> Zhang Xiaoyu 390320151 :155:90:201
> Meng Waiwai 70271111 :250:80:75
> Wu Feixue 80042789 :250:60:50
> Liu Bingbing 41117483 :250:100:175
> Wang Xiaoai 3515064655 :50:168:200
> Zi Gege 1986787350 :250:168:200
> Li Youjiu 918391635 :175:75:300
> Lao Nanhai 918391635 :250:100:175
> EOF

cp awk_test.txt{,.bak}    # 备份源文件
column -t awk_test.txt.bak > awk_test.txt    # 见文件内容以表格形式展示
```

### 简单示例

```shell
# 示例：显示Xiaoyu的姓和ID
awk '/Xiaoyu/{print $1, $3}' awk_test.txt
    # 使用-F指定分隔符信息时，awk默认使用空格作为分隔列，且多个空格信息默认看作一个整体
    # awk默认将逗号识别成空格符号，如果需要将其识别为逗号，需要用引号包裹逗号
awk 'NR==2{print $1,$3}' awk_test.txt    # 另一种方式实现效果

# 示例：显示所有Zhang姓，并显示第二次捐款金额及名称
awk -F "[ :]+" '/Zhang/{print $2,$5}' awk_test.txt
    # 使用awk输出列信息时总是从左往右数，awk默认也可以从右往左数，需要用到参数$NF（Number Field）
awk -F "[ :]+" '/Zhang/{print $2,$(NF-1)}' awk_test.txt    # 另一种实现方式
    # 默认情况下NF代表最后一行，如果要取倒数第2行，则用NF-1即可，很明显awk的字符运算优先级高于算数运算，所有NF-1需要括号

# 示例：显示所有以41开头的ID号的人的全名和ID号
awk '$3~/^41/{print $1,$2,$3}' awk_test.txt | column -t
    # 默认情况下正则符^和$在awk中的作用与sed一样，都表示匹配一行的行首和行尾字符，但在awk中，这两个符号可以更加精准的匹配到某一列的行首字符和行尾字符
    # 例如此例中，'$3~/^41/'表示匹配第3列以41开头的内容，其中~用于连接两者的意义
awk '$3!~/^41/{print $1,$2,$3}' awk_test.txt | column -t    # 取反示例

# 示例：显示所有ID号最后一位数字时1或5的人的全名
awk '$3~/1$|5$/{print $1,$2}' awk_test.txt | column -t
awk '$3~/(1|5)$/{print $1,$2}' awk_test.txt    # 简化通用的$符
awk '$3~/[15]$/{print $1,$2}' awk_test.txt

# 示例：显示Xiaoyu的捐款，每个值前面都已$开头
gawk '/Xiaoyu/{gsub(/:/,"$",$4);print $1,$2,$4}' awk_test.txt
    # awk替换操作语法：'{gsub(/要替换的信息/,"替换成什么",要替换第几列信息)}'
    # echo oldboy | awk '{gsub(/oldboy/,"oleboy",$1);print $1}'    # 替换示例，gsub在awk中也是一个指令，所以gsub与print需要使用;号分隔
```

## awk模式说明

### 普通模式

- 正则表达式模式

  作为基本模式，最普遍的应用就是利用正则表达式作为匹配条件，搜索行内容

- 比较表达式模式

  在一定范围内匹配条件。类似sed的行范围搜索

  ```shell
  awk 'NR>2{print $0}' awk.txt    # 从第3行开始匹配条件.$0表示显示所有列信息
  ```

- 范围模式

  ```shell
  awk 'NR==1,NR==3{print $0}' awk.txt    # 具体范围显示
  ```

### 特殊模式

- BEGIN模式：在文件处理前，执行相应操作；多用于测试、计算和修改内置变量
- END模式：在文件处理后，执行相应操作；多用于计算、显示计算结果

特殊模式示例：

```shell
awk 'BEGIN{print "oldboy123"}NR>2{print $0}END{print "oleboy456"}' awk.txt | column -t    # 在过滤的文本内容前后都补充一行内容
```

> **补充：for循环语法**

```shell
# for语法：for 变量 in 取值范围;do 执行指令;done
for i in {1..10}; do echo $i; done
```

## awk运算方式

示例：计算`/etc/services`文件中的空行

```shell
grep -c "^$" /etc/services
```

### 累加运算（计数）

```shell
# 示例：计算文件空行信息
awk '/^$/{i=i+1; print $i}' /etc/services    # 未给i设置初始值时，默认等于0。i=i+1可以替换为i++
awk '/^$/{i=i+1; print i}' /etc/services    # 输出了累加过程

awk '/^$/{i=i+1}END{print i}' /etc/services    # 正确示例。通过END关键词仅输出累加结果
```

在awk中调用变量信息时，直接调用变量名不需要加`$`符；在awk中输出字符信息时必须带上双引号，否则会被识别为变量名

#### 关于BEGIN的执行逻辑

```shell
awk '/^$/BEGIN{i=i+1; print $i}' /etc/services
```

语法错误，BEGIN模式是在文件处理前执行相应操作，语法上的重点在于文件处理前，将BEGIN关键词放在过滤符`/^$/`后面时，awk执行过滤时就表示已经读取了文件内容，读取文件内容后再执行BEGIN违背了BEGIN的语法规则

#### 关于内置变量

什么是内置变量，例如

- NR：行号信息
- NF：尾列
- FS：field separator，指定分隔符号，在awk中FS可以通过-F选项代替

示例：使用BEGIN修改内置变量

```shell
awk -F ":" '{print $1}' awk_test.txt    # 使用-F选项声明分隔符。等同于FS字段
awk 'BEGIN{FS=":"}{print $1}' awk_test.txt    # 使用BEGIN实现上例同样效果
awk -v FS=":" '{print $1}' awk_test.txt    # 实现上例同样效果

awk -v test=42 'END{print test}' awk_test.txt    # -v选项表示执行awk命令前，创建一个变量并赋值，awk命令可以直接调用此变量
    # 上例中如果不使用END关键字，则文件内容被读取多少行，就会输出多少次变量
```

### 求和运算（相加）

```shell
seq 10 | awk '{i=i+$0}END{print i}'    # 求1~10的和
seq 10 | awk '{i+=$0}END{print i}'    # 自加简化。要将第n列求和时，需要将$0修改为$n
```

## awk数组概念

1. 数组的组成说明

    数组名称[下标]

    ```shell
    awk 'BEGIN{h[110]="test"; h[111]="hebor"; print h[110],h[111]}'    #数组的组成与输出
    ```

2. 利用数组累加运算

    示例：创建测试环境

    ```shell
    http://www.etiantian.org/index.html
    http://www.etiantian.org/1.html
    http://post.etiantian.org/index.html
    http://mp3.etiantian.org/index.html
    http://www.etiantian.org/3.html
    http://post.etiantian.org/2.html
    ```

    示例：`www`域名出现次数

    ```shell
    awk -F "[/.]+" '{array[$2]++; print array["www"]}' url.txt    # 输出累加过程。
    awk -F "[/.]+" '{array[$2]++}END{print array["www"]}' url.txt    # 输出累加结果
    ```

3. 数组循环

    ```shell
    # 仍以上例为准，上例中环境条目较少，能够直观的看出只有www、mp3、post三种类型，假设无法直观看出有多少种数据类型时，就需要用到数组循环
    awk -F "[/.]+" '{array[$2]} END{for (i in array) print i}' url.txt    # for循环遍历数组中的值，并打印输出
    awk -F "[/.]+" '{array[$2]++} END{for (i in array) print array[i]}' url.txt    # for循环累加计算每种数据类型出现过多少次
    awk -F "[/.]+" '{array[$2]++} END{for (i in array) print i,array[i]}' url.txt    # 最终结果，一一对应

    # 过滤secure日志文件里的IP出现次数
    awk -F "(from)|(port)" '/Failed password/{array[$2]++} END{for (ip in array) print ip,array[ip]}' secure
    awk '/Failed password/{array[$(NF-3)]++} END{for (ip in array) print ip,array[ip]}' secure    # 另一种写法
    ```

4. 数组排序

    ```shell
    # 查询登录失败的IP
    awk '/Failed password/{array[$(NF-3)]++} END{for (ip in array) print ip,array[ip]}' secure | column -t | sort -rnk 2

    # 查询登录失败使用的用户名
    awk '/Failed password/{array[$(NF-5)]++} END{for (name in array) print name,array[name]}' secure | column -t | sort -rnk 2
    ``

    示例：对web服务的`access.log`日志文件做数据统计

    ```shell
    # 1.每个ip地址的访问次数
    awk '{array[$1]++} END{for (ip in array) print ip,array[ip]}' access.log

    # 2.每个ip地址使用了多少流量


    # 3.每个ip地址访问的次数，同时统计每个ip地址使用了多少流量
    ```

    由于日志文件的信息记录不完整，此实例中仅展示统计方法